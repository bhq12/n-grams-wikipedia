# n-grams-wikipedia
An n-gram language model based on a wikipedia dump corpus

NOTE: The setup script will download and extract ~150GB of text files, be prepared with enough disk space.
